{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating network model using gpu 0\n",
      "Finished setup of GPU\n"
     ]
    }
   ],
   "source": [
    "from configGAN import *\n",
    "import setupGPU\n",
    "cfg = flying_objects_config()\n",
    "cfg.GPU = 1\n",
    "setupGPU.setup_GPU(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utilsGAN import *\n",
    "from improvedUtils import preprocess, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "##################### Training Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 10817\n",
      "total class number \t 3\n",
      "class square \t 3488 images\n",
      "class circular \t 3626 images\n",
      "class triangle \t 3703 images\n",
      "######################################################################\n",
      "\n",
      "######################################################################\n",
      "##################### Validation Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 2241\n",
      "total class number \t 3\n",
      "class triangle \t 745 images\n",
      "class square \t 783 images\n",
      "class circular \t 713 images\n",
      "######################################################################\n",
      "\n",
      "######################################################################\n",
      "##################### Testing Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 2220\n",
      "total class number \t 3\n",
      "class triangle \t 733 images\n",
      "class square \t 765 images\n",
      "class circular \t 722 images\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "show_statistics(cfg.training_data_dir, fineGrained=False, title=\" Training Data Statistics \")\n",
    "show_statistics(cfg.validation_data_dir, fineGrained=False, title=\" Validation Data Statistics \")\n",
    "show_statistics(cfg.testing_data_dir, fineGrained=False, title=\" Testing Data Statistics \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_training(train_class, model):\n",
    "    log_dir = logger(model.__name__)\n",
    "    print(f\"\\nSetting up training environment: Train: {train_class.__name__} Model: {model.__name__}\\n{'-'*40}\\nlog_dir: {log_dir}\")\n",
    "    train_batch_generator, valid_batch_generator, test_batch_generator, nbr_train_data,nbr_valid_data, nbr_test_data = preprocess(image_shape, normalize_type=model.__norm__, jitter=model.__jitter__, cfg=cfg)\n",
    "    gan = train_class.start_train(\n",
    "        model, \n",
    "        cfg, \n",
    "        log_dir=log_dir,\n",
    "        train_batch_generator=train_batch_generator,\n",
    "        valid_batch_generator=valid_batch_generator,\n",
    "        nbr_train_data=nbr_train_data,\n",
    "        nbr_valid_data=nbr_valid_data\n",
    "    )\n",
    "    return gan\n",
    "\n",
    "def init_models(model_class):\n",
    "    train_class = train_class = train.allowed[model_class.__train__]\n",
    "    start_training(train_class, model_class(image_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and GAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allowed models:\n",
      "------------\n",
      "default_model_v0\n",
      "Pix2Pix_model_v1\n",
      "Pix2Pix_model_v10\n",
      "Pix2Pix_model_v11\n",
      "Pix2Pix_model_v12\n",
      "Pix2Pix_model_v2\n",
      "Pix2Pix_model_v3\n",
      "Pix2Pix_model_v5\n",
      "Pix2Pix_model_v6\n",
      "Pix2Pix_model_v7\n",
      "Pix2Pix_model_v8\n",
      "Pix2Pix_model_v9\n",
      "Pix2Pix_wasserstein_model_v4\n",
      "segmentation_model_v1\n",
      "segmentation_model_v2\n",
      "\n",
      "Allowed train:\n",
      "------------\n",
      "pix2pix_minibatches\n",
      "pix2pix\n",
      "wasserstein\n"
     ]
    }
   ],
   "source": [
    "print(\"Allowed models:\\n------------\",*models.allowed, sep=\"\\n\")\n",
    "print(\"\\nAllowed train:\\n------------\",*train.allowed, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH, cfg.IMAGE_CHANNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_class = models.allowed['Pix2Pix_model_v6']\n",
    "#train_class = train.allowed[model_class.__train__]\n",
    "#start_training(train_class, model_class(image_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for model_class in list(models.allowed.values())[6]:\n",
    "#    train_class = train_class = train.allowed[model_class.__train__]\n",
    "#    start_training(train_class, model_class(image_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up training environment: Train: pix2pix Model: Pix2Pix_model_v11\n",
      "----------------------------------------\n",
      "log_dir: ./logs/20210106-203250.Pix2Pix_model_v11\n",
      "train_x (30, 128, 128, 3) float32 -1.0 1.0\n",
      "train_y (30, 128, 128, 3) float32 -1.0 1.0\n",
      "{'BATCH_SIZE': 30,\n",
      " 'DATA_AUGMENTATION': True,\n",
      " 'DEBUG_MODE': True,\n",
      " 'DROPOUT_PROB': 0.5,\n",
      " 'GPU': 0,\n",
      " 'IMAGE_CHANNEL': 3,\n",
      " 'IMAGE_HEIGHT': 128,\n",
      " 'IMAGE_WIDTH': 128,\n",
      " 'LEARNING_RATE': 0.01,\n",
      " 'LR_DECAY_FACTOR': 0.1,\n",
      " 'NUM_EPOCHS': 200,\n",
      " 'PRINT_EVERY': 50,\n",
      " 'SAVE_EVERY': 1,\n",
      " 'SEQUENCE_LENGTH': 10,\n",
      " 'testing_data_dir': '../data/FlyingObjectDataset_10K/testing',\n",
      " 'training_data_dir': '../data/FlyingObjectDataset_10K/training',\n",
      " 'validation_data_dir': '../data/FlyingObjectDataset_10K/validation'}\n",
      "\n",
      "Starting to train model..\n",
      "Epoch 1/200\n",
      "  1/360 [..............................] - ETA: 0s - gen_total_loss: 100.6446 - gen_gan_loss: 0.8205 - gen_l1_loss: 0.9982 - disc_loss: 1.7345WARNING:tensorflow:From /home/stud/f/fremar16/miniconda3/envs/lab/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/360 [..............................] - ETA: 3:14 - gen_total_loss: 96.3828 - gen_gan_loss: 1.3269 - gen_l1_loss: 0.9506 - disc_loss: 2.4993WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0758s vs `on_train_batch_begin` time: 0.7352s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0758s vs `on_train_batch_end` time: 0.2749s). Check your callbacks.\n",
      "360/360 [==============================] - 227s 629ms/step - gen_total_loss: 10.3975 - gen_gan_loss: 1.0548 - gen_l1_loss: 0.0934 - disc_loss: 1.2657 - val_accuracy: 0.4338 - val_ssim2: 0.9253 - val_psnr2: 0.2073\n",
      "Epoch 2/200\n",
      "360/360 [==============================] - 104s 290ms/step - gen_total_loss: 5.4206 - gen_gan_loss: 0.8884 - gen_l1_loss: 0.0453 - disc_loss: 1.2924 - val_accuracy: 0.1472 - val_ssim2: 0.8576 - val_psnr2: 0.1334\n",
      "Epoch 3/200\n",
      "360/360 [==============================] - 97s 269ms/step - gen_total_loss: 4.9435 - gen_gan_loss: 0.8814 - gen_l1_loss: 0.0406 - disc_loss: 1.2872 - val_accuracy: 0.4625 - val_ssim2: 0.9414 - val_psnr2: 0.2185\n",
      "Epoch 4/200\n",
      "360/360 [==============================] - 96s 266ms/step - gen_total_loss: 4.6975 - gen_gan_loss: 0.8649 - gen_l1_loss: 0.0383 - disc_loss: 1.2941 - val_accuracy: 0.7485 - val_ssim2: 0.9455 - val_psnr2: 0.2215\n",
      "Epoch 5/200\n",
      "360/360 [==============================] - 97s 268ms/step - gen_total_loss: 4.3878 - gen_gan_loss: 0.8403 - gen_l1_loss: 0.0355 - disc_loss: 1.3070 - val_accuracy: 0.2150 - val_ssim2: 0.9495 - val_psnr2: 0.2252\n",
      "Epoch 6/200\n",
      "360/360 [==============================] - 97s 268ms/step - gen_total_loss: 4.1304 - gen_gan_loss: 0.8318 - gen_l1_loss: 0.0330 - disc_loss: 1.3135 - val_accuracy: 0.1609 - val_ssim2: 0.9495 - val_psnr2: 0.2272\n",
      "Epoch 7/200\n",
      "360/360 [==============================] - 96s 266ms/step - gen_total_loss: 3.9236 - gen_gan_loss: 0.8203 - gen_l1_loss: 0.0310 - disc_loss: 1.3138 - val_accuracy: 0.1922 - val_ssim2: 0.9454 - val_psnr2: 0.2187\n",
      "Epoch 8/200\n",
      "360/360 [==============================] - 96s 267ms/step - gen_total_loss: 3.6743 - gen_gan_loss: 0.8247 - gen_l1_loss: 0.0285 - disc_loss: 1.3108 - val_accuracy: 0.1807 - val_ssim2: 0.9535 - val_psnr2: 0.2314\n",
      "Epoch 9/200\n",
      "360/360 [==============================] - 96s 268ms/step - gen_total_loss: 3.5125 - gen_gan_loss: 0.8297 - gen_l1_loss: 0.0268 - disc_loss: 1.3109 - val_accuracy: 0.2687 - val_ssim2: 0.9270 - val_psnr2: 0.1882\n",
      "Epoch 10/200\n",
      "360/360 [==============================] - 95s 264ms/step - gen_total_loss: 3.3812 - gen_gan_loss: 0.8396 - gen_l1_loss: 0.0254 - disc_loss: 1.3072 - val_accuracy: 0.2346 - val_ssim2: 0.9543 - val_psnr2: 0.2316\n",
      "Epoch 11/200\n",
      " 69/360 [====>.........................] - ETA: 1:07 - gen_total_loss: 3.5195 - gen_gan_loss: 0.8546 - gen_l1_loss: 0.0266 - disc_loss: 1.2737"
     ]
    }
   ],
   "source": [
    "init_models(models.allowed['Pix2Pix_model_v3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
