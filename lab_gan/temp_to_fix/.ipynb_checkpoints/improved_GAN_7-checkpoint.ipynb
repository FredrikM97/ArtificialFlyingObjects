{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configGAN import *\n",
    "cfg = flying_objects_config()\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from utilsGAN import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "from datetime import datetime\n",
    "import imageio\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "import pprint\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv3D, Conv2D, Conv1D, Convolution2D, Deconvolution2D, Cropping2D, UpSampling2D\n",
    "from keras.layers import Input, Conv2DTranspose, ConvLSTM2D, TimeDistributed, GlobalMaxPooling2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Concatenate, concatenate, Reshape\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.layers import Input, merge\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout, LeakyReLU\n",
    "import keras.backend as kb\n",
    "from tensorflow.python.keras.engine import compile_utils\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating network model using gpu 0\n"
     ]
    }
   ],
   "source": [
    "def limit_gpu():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "limit_gpu()\n",
    "\n",
    "if cfg.GPU >=0:\n",
    "    print(\"creating network model using gpu \" + str(cfg.GPU))\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(cfg.GPU)\n",
    "elif cfg.GPU >=-1:\n",
    "    print(\"creating network model using cpu \")  \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "##################### Training Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 10817\n",
      "total class number \t 3\n",
      "class square \t 3488 images\n",
      "class circular \t 3626 images\n",
      "class triangle \t 3703 images\n",
      "######################################################################\n",
      "\n",
      "######################################################################\n",
      "##################### Validation Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 2241\n",
      "total class number \t 3\n",
      "class triangle \t 745 images\n",
      "class square \t 783 images\n",
      "class circular \t 713 images\n",
      "######################################################################\n",
      "\n",
      "######################################################################\n",
      "##################### Testing Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 2220\n",
      "total class number \t 3\n",
      "class triangle \t 733 images\n",
      "class square \t 765 images\n",
      "class circular \t 722 images\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "show_statistics(cfg.training_data_dir, fineGrained=False, title=\" Training Data Statistics \")\n",
    "show_statistics(cfg.validation_data_dir, fineGrained=False, title=\" Validation Data Statistics \")\n",
    "show_statistics(cfg.testing_data_dir, fineGrained=False, title=\" Testing Data Statistics \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_shape = (cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH, cfg.IMAGE_CHANNEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare plots and logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from improvedUtils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class architecture:\n",
    "    __name__='Pix2Pix_model_v2'\n",
    "    __changes__=\"Changed to a pix2pix model in order to test a greater network for generator and discriminator. Generator: U-Net, Discriminator: PatchGAN. Changed Discriminator optimizer to SGD\"\n",
    "    \n",
    "    __normalization__='[-1,1]'\n",
    "    \n",
    "    generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    discriminator_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "    \n",
    "    @staticmethod\n",
    "    def discriminator():\n",
    "        def downsample(filters, size, apply_batchnorm=True):\n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "            result = tf.keras.Sequential()\n",
    "            result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                     kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "            if apply_batchnorm:\n",
    "                result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "            result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "            return result\n",
    "        \n",
    "        def main():\n",
    "            \n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "            inp = tf.keras.layers.Input(shape=image_shape, name='input_image')\n",
    "            tar = tf.keras.layers.Input(shape=image_shape, name='target_image')\n",
    "\n",
    "            x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "            down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
    "            down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "            down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "            zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "            conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "            batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "            leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "            zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "            last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                        kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "            return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
    "        \n",
    "        \n",
    "        return main()\n",
    "    \n",
    "    @staticmethod\n",
    "    def generator():\n",
    "        def downsample(filters, size, apply_batchnorm=True):\n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "            result = tf.keras.Sequential()\n",
    "            result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                     kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "            if apply_batchnorm:\n",
    "                result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "            result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "            return result\n",
    "        \n",
    "        def upsample(filters, size, apply_dropout=False):\n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "            result = tf.keras.Sequential()\n",
    "            result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                            padding='same',\n",
    "                                            kernel_initializer=initializer,\n",
    "                                            use_bias=False))\n",
    "\n",
    "            result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "            if apply_dropout:\n",
    "                result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "            result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "            return result\n",
    "\n",
    "        def main():\n",
    "            inputs = tf.keras.layers.Input(shape=image_shape)\n",
    "\n",
    "            down_stack = [\n",
    "                downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "                downsample(128, 4), # (bs, 64, 64, 128)\n",
    "                downsample(256, 4), # (bs, 32, 32, 256)\n",
    "                downsample(512, 4), # (bs, 16, 16, 512)\n",
    "                downsample(512, 4), # (bs, 8, 8, 512)\n",
    "                downsample(512, 4), # (bs, 4, 4, 512)\n",
    "                downsample(512, 4), # (bs, 2, 2, 512)\n",
    "                #downsample(512, 4), # (bs, 1, 1, 512)\n",
    "            ]\n",
    "\n",
    "            up_stack = [\n",
    "                upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "                upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "                upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "                upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "                upsample(256, 4), # (bs, 32, 32, 512)\n",
    "                upsample(128, 4), # (bs, 64, 64, 256)\n",
    "                upsample(64, 4), # (bs, 128, 128, 128)\n",
    "            ]\n",
    "\n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "            last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                                 strides=2,\n",
    "                                                 padding='same',\n",
    "                                                 kernel_initializer=initializer,\n",
    "                                                 activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "            x = inputs\n",
    "\n",
    "            # Downsampling through the model\n",
    "            skips = []\n",
    "            for down in down_stack:\n",
    "                x = down(x)\n",
    "                skips.append(x)\n",
    "\n",
    "            skips = reversed(skips[:-1])\n",
    "\n",
    "            # Upsampling and establishing the skip connections\n",
    "            for up, skip in zip(up_stack, skips):\n",
    "                x = up(x)\n",
    "                x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "            x = last(x)\n",
    "\n",
    "            return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "        return main()\n",
    "    \n",
    "    def loss():  # Decided by https://arxiv.org/abs/1611.07004\n",
    "        loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        LAMBDA = 100\n",
    "        def generator_loss(disc_generated_output, gen_output, target): # https://arxiv.org/abs/1611.07004\n",
    "            gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "            # mean absolute error\n",
    "            l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "            total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "            return total_gen_loss, gan_loss, l1_loss\n",
    "\n",
    "        def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "            real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "            generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "            total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "            return total_disc_loss\n",
    "\n",
    "        return {'g_loss_fn':generator_loss, 'd_loss_fn':discriminator_loss}\n",
    "    \n",
    "    def __model__():\n",
    "        return [architecture.generator, architecture.discriminator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x (30, 128, 128, 3) float32 -1.0 1.0\n",
      "train_y (30, 128, 128, 3) float32 -1.0 1.0\n",
      "{'BATCH_SIZE': 30,\n",
      " 'DATA_AUGMENTATION': True,\n",
      " 'DEBUG_MODE': True,\n",
      " 'DROPOUT_PROB': 0.5,\n",
      " 'GPU': 0,\n",
      " 'IMAGE_CHANNEL': 3,\n",
      " 'IMAGE_HEIGHT': 128,\n",
      " 'IMAGE_WIDTH': 128,\n",
      " 'LEARNING_RATE': 0.01,\n",
      " 'LR_DECAY_FACTOR': 0.1,\n",
      " 'NUM_EPOCHS': 200,\n",
      " 'PRINT_EVERY': 50,\n",
      " 'SAVE_EVERY': 1,\n",
      " 'SEQUENCE_LENGTH': 10,\n",
      " 'testing_data_dir': '../data/FlyingObjectDataset_10K/testing',\n",
      " 'training_data_dir': '../data/FlyingObjectDataset_10K/training',\n",
      " 'validation_data_dir': '../data/FlyingObjectDataset_10K/validation'}\n"
     ]
    }
   ],
   "source": [
    "train_batch_generator, valid_batch_generator, test_batch_generator, nbr_train_data,nbr_valid_data, nbr_test_data = preprocess(image_shape, normalize_type=architecture.__normalization__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        #self.epoch = 0\n",
    "    \n",
    "    def special_compile(self, \n",
    "                d_optimizer=None, \n",
    "                g_optimizer=None,\n",
    "                d_loss=None,\n",
    "                g_loss=None,               \n",
    "                loss_fn=None,\n",
    "                metrics=None,\n",
    "                loss_weights=None,\n",
    "                weighted_metrics=None,\n",
    "                run_eagerly=None,\n",
    "                steps_per_execution=None,\n",
    "              **kwargs):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss = d_loss\n",
    "        self.g_loss = g_loss\n",
    "        \n",
    "        super().compile(metrics=metrics)\n",
    "    \n",
    "    def compile(self, **kwargs):\n",
    "        raise NotImplementedError(\"Please use special_compile()\")\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data): \n",
    "        #self.epoch += 1\n",
    "        input_image, target = data # TODO: Must check if this iterates or take same image each run\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            \n",
    "            # Generate images\n",
    "            gen_output = self.generator(input_image, training=True)\n",
    "            \n",
    "            # Train discriminator\n",
    "            disc_real_output = self.discriminator([input_image, target], training=True)\n",
    "            disc_generated_output = self.discriminator([input_image, gen_output], training=True)\n",
    "            \n",
    "            # Training\n",
    "            gen_total_loss, gen_gan_loss, gen_l1_loss = self.g_loss(disc_generated_output, gen_output, target)\n",
    "            disc_loss = self.d_loss(disc_real_output, disc_generated_output)\n",
    "            \n",
    "            # Set weights\n",
    "            generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                              self.generator.trainable_variables)\n",
    "            discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                                   self.discriminator.trainable_variables)\n",
    "            # Update weights\n",
    "            self.g_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                              self.generator.trainable_variables))\n",
    "            self.d_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                                  self.discriminator.trainable_variables))\n",
    "            \n",
    "        self.compiled_metrics.update_state(target, gen_output)\n",
    "        \n",
    "        met = {\n",
    "                'gen_total_loss':gen_total_loss,\n",
    "                'gen_gan_loss':gen_gan_loss,\n",
    "                'gen_l1_loss':gen_l1_loss,\n",
    "                'disc_loss':disc_loss, \n",
    "                \n",
    "        }\n",
    "        met.update({m.name: m.result() for m in self.metrics})\n",
    "        return met\n",
    "    \n",
    "\n",
    "    def test_step(self, data):\n",
    "        real_images, last_images = data\n",
    "        valid, fake_last_frame = self(real_images, training=False)\n",
    "\n",
    "        self.compiled_metrics.update_state(real_images, fake_last_frame)\n",
    "            \n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def call(self, first_frame, training=False):\n",
    "        fake_last_frame = self.generator(first_frame, training)\n",
    "        validate_frame = self.discriminator([fake_last_frame, first_frame], training)\n",
    "        \n",
    "        return [validate_frame, fake_last_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  1/360 [..............................] - ETA: 0s - gen_total_loss: 101.0597 - gen_gan_loss: 0.5846 - gen_l1_loss: 1.0048 - disc_loss: 1.8360 - accuracy: 0.1929 - SSIM_loss: 1.0017WARNING:tensorflow:From /home/stud/f/fremar16/miniconda3/envs/lab/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/360 [..............................] - ETA: 1:08 - gen_total_loss: 96.7980 - gen_gan_loss: 0.8414 - gen_l1_loss: 0.9596 - disc_loss: 1.8332 - accuracy: 0.1951 - SSIM_loss: 0.9933WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1050s vs `on_train_batch_end` time: 0.2739s). Check your callbacks.\n",
      "360/360 [==============================] - 149s 415ms/step - gen_total_loss: 10.7761 - gen_gan_loss: 1.2574 - gen_l1_loss: 0.0952 - disc_loss: 1.3252 - accuracy: 0.2798 - SSIM_loss: 0.1359 - val_accuracy: 0.5330 - val_SSIM_loss: 0.0744\n",
      "Epoch 2/200\n",
      "360/360 [==============================] - 94s 261ms/step - gen_total_loss: 6.0705 - gen_gan_loss: 0.9959 - gen_l1_loss: 0.0507 - disc_loss: 1.3735 - accuracy: 0.3301 - SSIM_loss: 0.0777 - val_accuracy: 0.3134 - val_SSIM_loss: 0.0983\n",
      "Epoch 3/200\n",
      "360/360 [==============================] - 148s 411ms/step - gen_total_loss: 4.8751 - gen_gan_loss: 0.8264 - gen_l1_loss: 0.0405 - disc_loss: 1.3779 - accuracy: 0.3412 - SSIM_loss: 0.0649 - val_accuracy: 0.2255 - val_SSIM_loss: 0.0804\n",
      "Epoch 4/200\n",
      "360/360 [==============================] - 149s 414ms/step - gen_total_loss: 4.3428 - gen_gan_loss: 0.7988 - gen_l1_loss: 0.0354 - disc_loss: 1.3851 - accuracy: 0.3546 - SSIM_loss: 0.0585 - val_accuracy: 0.2182 - val_SSIM_loss: 0.0765\n",
      "Epoch 5/200\n",
      "360/360 [==============================] - 95s 264ms/step - gen_total_loss: 3.9578 - gen_gan_loss: 0.7896 - gen_l1_loss: 0.0317 - disc_loss: 1.3746 - accuracy: 0.3651 - SSIM_loss: 0.0540 - val_accuracy: 0.1758 - val_SSIM_loss: 0.0571\n",
      "Epoch 6/200\n",
      "360/360 [==============================] - 90s 249ms/step - gen_total_loss: 3.6492 - gen_gan_loss: 0.7879 - gen_l1_loss: 0.0286 - disc_loss: 1.3765 - accuracy: 0.3757 - SSIM_loss: 0.0501 - val_accuracy: 0.7951 - val_SSIM_loss: 0.0457\n",
      "Epoch 7/200\n",
      "360/360 [==============================] - 90s 250ms/step - gen_total_loss: 3.3865 - gen_gan_loss: 0.7716 - gen_l1_loss: 0.0261 - disc_loss: 1.3883 - accuracy: 0.4074 - SSIM_loss: 0.0470 - val_accuracy: 0.3554 - val_SSIM_loss: 0.0638\n",
      "Epoch 8/200\n",
      "360/360 [==============================] - 92s 255ms/step - gen_total_loss: 3.2226 - gen_gan_loss: 0.7537 - gen_l1_loss: 0.0247 - disc_loss: 1.3827 - accuracy: 0.4008 - SSIM_loss: 0.0447 - val_accuracy: 0.6462 - val_SSIM_loss: 0.0768\n",
      "Epoch 9/200\n",
      "360/360 [==============================] - 100s 279ms/step - gen_total_loss: 3.0348 - gen_gan_loss: 0.7452 - gen_l1_loss: 0.0229 - disc_loss: 1.3883 - accuracy: 0.4348 - SSIM_loss: 0.0423 - val_accuracy: 0.5393 - val_SSIM_loss: 0.0756\n",
      "Epoch 10/200\n",
      "360/360 [==============================] - 109s 302ms/step - gen_total_loss: 2.9218 - gen_gan_loss: 0.7399 - gen_l1_loss: 0.0218 - disc_loss: 1.3862 - accuracy: 0.4500 - SSIM_loss: 0.0406 - val_accuracy: 0.2838 - val_SSIM_loss: 0.0609\n",
      "Epoch 11/200\n",
      "360/360 [==============================] - 103s 287ms/step - gen_total_loss: 2.8396 - gen_gan_loss: 0.7416 - gen_l1_loss: 0.0210 - disc_loss: 1.3859 - accuracy: 0.4507 - SSIM_loss: 0.0393 - val_accuracy: 0.5405 - val_SSIM_loss: 0.0499\n",
      "Epoch 12/200\n",
      "360/360 [==============================] - 105s 292ms/step - gen_total_loss: 2.8308 - gen_gan_loss: 0.7374 - gen_l1_loss: 0.0209 - disc_loss: 1.3808 - accuracy: 0.4606 - SSIM_loss: 0.0389 - val_accuracy: 0.4018 - val_SSIM_loss: 0.0831\n",
      "Epoch 13/200\n",
      "360/360 [==============================] - 101s 280ms/step - gen_total_loss: 2.6258 - gen_gan_loss: 0.7337 - gen_l1_loss: 0.0189 - disc_loss: 1.3832 - accuracy: 0.4477 - SSIM_loss: 0.0360 - val_accuracy: 0.1646 - val_SSIM_loss: 0.0590\n",
      "Epoch 14/200\n",
      "360/360 [==============================] - 101s 281ms/step - gen_total_loss: 2.6113 - gen_gan_loss: 0.7311 - gen_l1_loss: 0.0188 - disc_loss: 1.3827 - accuracy: 0.4652 - SSIM_loss: 0.0356 - val_accuracy: 0.3143 - val_SSIM_loss: 0.0660\n",
      "Epoch 15/200\n",
      "360/360 [==============================] - 100s 277ms/step - gen_total_loss: 2.5778 - gen_gan_loss: 0.7302 - gen_l1_loss: 0.0185 - disc_loss: 1.3857 - accuracy: 0.4701 - SSIM_loss: 0.0350 - val_accuracy: 0.3165 - val_SSIM_loss: 0.0458\n",
      "Epoch 16/200\n",
      "360/360 [==============================] - 112s 311ms/step - gen_total_loss: 2.4851 - gen_gan_loss: 0.7306 - gen_l1_loss: 0.0175 - disc_loss: 1.3828 - accuracy: 0.4588 - SSIM_loss: 0.0336 - val_accuracy: 0.6732 - val_SSIM_loss: 0.0611\n",
      "Epoch 17/200\n",
      "360/360 [==============================] - 154s 427ms/step - gen_total_loss: 2.3776 - gen_gan_loss: 0.7259 - gen_l1_loss: 0.0165 - disc_loss: 1.3859 - accuracy: 0.4551 - SSIM_loss: 0.0319 - val_accuracy: 0.5310 - val_SSIM_loss: 0.0679\n",
      "Epoch 18/200\n",
      "360/360 [==============================] - 155s 431ms/step - gen_total_loss: 2.3451 - gen_gan_loss: 0.7256 - gen_l1_loss: 0.0162 - disc_loss: 1.3826 - accuracy: 0.4711 - SSIM_loss: 0.0312 - val_accuracy: 0.3652 - val_SSIM_loss: 0.0543\n",
      "Epoch 19/200\n",
      "360/360 [==============================] - 147s 408ms/step - gen_total_loss: 2.3996 - gen_gan_loss: 0.7260 - gen_l1_loss: 0.0167 - disc_loss: 1.3811 - accuracy: 0.4522 - SSIM_loss: 0.0316 - val_accuracy: 0.4319 - val_SSIM_loss: 0.0684\n",
      "Epoch 20/200\n",
      "360/360 [==============================] - 150s 417ms/step - gen_total_loss: 2.2627 - gen_gan_loss: 0.7225 - gen_l1_loss: 0.0154 - disc_loss: 1.3818 - accuracy: 0.4690 - SSIM_loss: 0.0298 - val_accuracy: 0.2620 - val_SSIM_loss: 0.0567\n",
      "Epoch 21/200\n",
      "360/360 [==============================] - 149s 415ms/step - gen_total_loss: 2.2779 - gen_gan_loss: 0.7275 - gen_l1_loss: 0.0155 - disc_loss: 1.3823 - accuracy: 0.4898 - SSIM_loss: 0.0299 - val_accuracy: 0.2827 - val_SSIM_loss: 0.0765\n",
      "Epoch 22/200\n",
      "360/360 [==============================] - 149s 413ms/step - gen_total_loss: 2.2027 - gen_gan_loss: 0.7213 - gen_l1_loss: 0.0148 - disc_loss: 1.3827 - accuracy: 0.4785 - SSIM_loss: 0.0288 - val_accuracy: 0.3560 - val_SSIM_loss: 0.0771\n",
      "Epoch 23/200\n",
      "360/360 [==============================] - 149s 413ms/step - gen_total_loss: 2.2160 - gen_gan_loss: 0.7223 - gen_l1_loss: 0.0149 - disc_loss: 1.3823 - accuracy: 0.4812 - SSIM_loss: 0.0287 - val_accuracy: 0.3654 - val_SSIM_loss: 0.0544\n",
      "Epoch 24/200\n",
      "360/360 [==============================] - 150s 416ms/step - gen_total_loss: 2.1752 - gen_gan_loss: 0.7214 - gen_l1_loss: 0.0145 - disc_loss: 1.3808 - accuracy: 0.4944 - SSIM_loss: 0.0281 - val_accuracy: 0.6188 - val_SSIM_loss: 0.0834\n",
      "Epoch 25/200\n",
      "360/360 [==============================] - 150s 417ms/step - gen_total_loss: 2.1048 - gen_gan_loss: 0.7187 - gen_l1_loss: 0.0139 - disc_loss: 1.3826 - accuracy: 0.5298 - SSIM_loss: 0.0270 - val_accuracy: 0.3212 - val_SSIM_loss: 0.0859\n",
      "Epoch 26/200\n",
      "360/360 [==============================] - 145s 404ms/step - gen_total_loss: 2.1497 - gen_gan_loss: 0.7183 - gen_l1_loss: 0.0143 - disc_loss: 1.3812 - accuracy: 0.5052 - SSIM_loss: 0.0274 - val_accuracy: 0.5503 - val_SSIM_loss: 0.0611\n",
      "Epoch 27/200\n",
      "360/360 [==============================] - 149s 413ms/step - gen_total_loss: 2.0235 - gen_gan_loss: 0.7146 - gen_l1_loss: 0.0131 - disc_loss: 1.3841 - accuracy: 0.5198 - SSIM_loss: 0.0259 - val_accuracy: 0.3635 - val_SSIM_loss: 0.0545\n",
      "Epoch 28/200\n",
      "360/360 [==============================] - 149s 413ms/step - gen_total_loss: 2.0049 - gen_gan_loss: 0.7167 - gen_l1_loss: 0.0129 - disc_loss: 1.3825 - accuracy: 0.5239 - SSIM_loss: 0.0255 - val_accuracy: 0.7357 - val_SSIM_loss: 0.0488\n",
      "Epoch 29/200\n",
      "360/360 [==============================] - 146s 407ms/step - gen_total_loss: 2.0258 - gen_gan_loss: 0.7160 - gen_l1_loss: 0.0131 - disc_loss: 1.3809 - accuracy: 0.5413 - SSIM_loss: 0.0256 - val_accuracy: 0.6193 - val_SSIM_loss: 0.0739\n",
      "Epoch 30/200\n",
      "360/360 [==============================] - 150s 416ms/step - gen_total_loss: 1.9555 - gen_gan_loss: 0.7161 - gen_l1_loss: 0.0124 - disc_loss: 1.3815 - accuracy: 0.5632 - SSIM_loss: 0.0246 - val_accuracy: 0.6251 - val_SSIM_loss: 0.0466\n",
      "Epoch 31/200\n",
      "360/360 [==============================] - 150s 416ms/step - gen_total_loss: 1.8951 - gen_gan_loss: 0.7149 - gen_l1_loss: 0.0118 - disc_loss: 1.3819 - accuracy: 0.5725 - SSIM_loss: 0.0238 - val_accuracy: 0.7129 - val_SSIM_loss: 0.0418\n",
      "Epoch 32/200\n",
      "360/360 [==============================] - 149s 413ms/step - gen_total_loss: 1.9509 - gen_gan_loss: 0.7145 - gen_l1_loss: 0.0124 - disc_loss: 1.3817 - accuracy: 0.5926 - SSIM_loss: 0.0245 - val_accuracy: 0.4031 - val_SSIM_loss: 0.0549\n",
      "Epoch 33/200\n",
      "360/360 [==============================] - 147s 408ms/step - gen_total_loss: 1.9725 - gen_gan_loss: 0.7156 - gen_l1_loss: 0.0126 - disc_loss: 1.3817 - accuracy: 0.6268 - SSIM_loss: 0.0246 - val_accuracy: 0.4065 - val_SSIM_loss: 0.0622\n",
      "Epoch 34/200\n",
      "203/360 [===============>..............] - ETA: 1:00 - gen_total_loss: 1.8626 - gen_gan_loss: 0.7116 - gen_l1_loss: 0.0115 - disc_loss: 1.3837 - accuracy: 0.6404 - SSIM_loss: 0.0232"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = (nbr_train_data // cfg.BATCH_SIZE) \n",
    "validation_steps=(nbr_valid_data//cfg.BATCH_SIZE)\n",
    "log_dir = logger(architecture().__name__)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, update_freq='epoch')\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/plots/\")\n",
    "\n",
    "generator, discriminator =  architecture.__model__()\n",
    "loss = architecture.loss()\n",
    "model_to_json(discriminator(), log_dir + \"/discriminator.json\")\n",
    "model_to_json(generator(), log_dir + \"/generator.json\")\n",
    "\n",
    "gan = GAN(discriminator=discriminator(), generator=generator())\n",
    "\n",
    "gan.special_compile(\n",
    "    d_optimizer=architecture.discriminator_optimizer,\n",
    "    g_optimizer=architecture.generator_optimizer,\n",
    "    d_loss=loss['d_loss_fn'],\n",
    "    g_loss=loss['g_loss_fn'],\n",
    "    metrics=['accuracy', SSIM_loss]\n",
    ")\n",
    "gan.fit(\n",
    "    x=train_batch_generator, \n",
    "    epochs=cfg.NUM_EPOCHS, \n",
    "    verbose=1, \n",
    "    batch_size=cfg.BATCH_SIZE,\n",
    "    steps_per_epoch=steps_per_epoch, #\n",
    "    validation_data=valid_batch_generator,\n",
    "    validation_steps=validation_steps, \n",
    "    callbacks=[GANMonitor(num_img=3, validation_data=valid_batch_generator,log_dir=log_dir), tensorboard_callback],\n",
    "    \n",
    ") \n",
    "\n",
    "\n",
    "with open(log_dir+\"/gan_finished\", 'a') as f:\n",
    "    f.write(architecture.__changes__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
