{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configGAN import *\n",
    "cfg = flying_objects_config()\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from utilsGAN import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "from datetime import datetime\n",
    "import imageio\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "import pprint\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv3D, Conv2D, Conv1D, Convolution2D, Deconvolution2D, Cropping2D, UpSampling2D\n",
    "from keras.layers import Input, Conv2DTranspose, ConvLSTM2D, TimeDistributed, GlobalMaxPooling2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Concatenate, concatenate, Reshape\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.layers import Input, merge\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout, LeakyReLU\n",
    "import keras.backend as kb\n",
    "from tensorflow.python.keras.engine import compile_utils\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating network model using gpu 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def limit_gpu():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "limit_gpu()\n",
    "\n",
    "if cfg.GPU >=0:\n",
    "    print(\"creating network model using gpu \" + str(cfg.GPU))\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(cfg.GPU)\n",
    "elif cfg.GPU >=-1:\n",
    "    print(\"creating network model using cpu \")  \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "##################### Training Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 10817\n",
      "total class number \t 3\n",
      "class square \t 3488 images\n",
      "class circular \t 3626 images\n",
      "class triangle \t 3703 images\n",
      "######################################################################\n",
      "\n",
      "######################################################################\n",
      "##################### Validation Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 2241\n",
      "total class number \t 3\n",
      "class triangle \t 745 images\n",
      "class square \t 783 images\n",
      "class circular \t 713 images\n",
      "######################################################################\n",
      "\n",
      "######################################################################\n",
      "##################### Testing Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 2220\n",
      "total class number \t 3\n",
      "class triangle \t 733 images\n",
      "class square \t 765 images\n",
      "class circular \t 722 images\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "show_statistics(cfg.training_data_dir, fineGrained=False, title=\" Training Data Statistics \")\n",
    "show_statistics(cfg.validation_data_dir, fineGrained=False, title=\" Validation Data Statistics \")\n",
    "show_statistics(cfg.testing_data_dir, fineGrained=False, title=\" Testing Data Statistics \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_shape = (cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH, cfg.IMAGE_CHANNEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare plots and logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from improvedUtils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class architecture:\n",
    "    __name__='default_model_v0'\n",
    "    __changes__=\"Default model given from teacher. Changed Discriminator optimizer to SGD. Disable Jitter\"\n",
    "    \n",
    "    __normalization__='[0,1]'\n",
    "    __jitter__= False\n",
    "    \n",
    "    generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    \n",
    "    @staticmethod\n",
    "    def discriminator():\n",
    "        def main():\n",
    "            last_img = Input(shape=image_shape)\n",
    "            first_img = Input(shape=image_shape)\n",
    "\n",
    "            # Concatenate image and conditioning image by channels to produce input\n",
    "            combined_imgs = Concatenate(axis=-1)([last_img, first_img])\n",
    "\n",
    "            d1 = Conv2D(32, (3, 3), strides=2, padding='same')(combined_imgs) \n",
    "            d1 = Activation('relu')(d1) \n",
    "            d2 = Conv2D(64, (3, 3), strides=2, padding='same')(d1)\n",
    "            d2 = Activation('relu')(d2) \n",
    "            d3 = Conv2D(128, (3, 3), strides=2, padding='same')(d2)\n",
    "            d3 = Activation('relu')(d3) \n",
    "\n",
    "            validity = Conv2D(1, (3, 3), strides=2, padding='same')(d3)\n",
    "\n",
    "            model = Model([last_img, first_img], validity)\n",
    "            return model\n",
    "        return main()\n",
    "    \n",
    "    @staticmethod\n",
    "    def generator():\n",
    "\n",
    "        def main():\n",
    "\n",
    "            inputs = Input(shape=image_shape)\n",
    "\n",
    "            down1 = Conv2D(32, (3, 3),padding='same')(inputs)\n",
    "            down1 = Activation('relu')(down1) \n",
    "            down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "\n",
    "            down2 = Conv2D(64, (3, 3), padding='same')(down1_pool)\n",
    "            down2 = Activation('relu')(down2) \n",
    "\n",
    "\n",
    "            up1 = UpSampling2D((2, 2))(down2)\n",
    "            up1 = concatenate([down1, up1], axis=3)\n",
    "            up1 = Conv2D(256, (3, 3), padding='same')(up1) \n",
    "            up1 = Activation('relu')(up1) \n",
    "\n",
    "\n",
    "            up2 = Conv2D(256, (3, 3), padding='same')(up1) \n",
    "            up2 = Activation('relu')(up2) \n",
    "\n",
    "            nbr_img_channels = image_shape[2]\n",
    "            outputs = Conv2D(nbr_img_channels, (1, 1), activation='sigmoid')(up2)\n",
    "\n",
    "            model = Model(inputs=inputs, outputs=outputs, name='Generator')\n",
    "            return model\n",
    "\n",
    "        return main()\n",
    "    \n",
    "    def loss():  # Decided by https://arxiv.org/abs/1611.07004\n",
    "        loss_object = tf.keras.losses.MeanSquaredError()\n",
    "        LAMBDA = 100\n",
    "        def generator_loss(disc_generated_output, gen_output, target): # https://arxiv.org/abs/1611.07004\n",
    "            gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "            # mean absolute error\n",
    "            l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "            total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "            return total_gen_loss, gan_loss, l1_loss\n",
    "\n",
    "        def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "            real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "            generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "            total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "            return total_disc_loss\n",
    "\n",
    "        return {'g_loss_fn':generator_loss, 'd_loss_fn':discriminator_loss}\n",
    "    \n",
    "    def __model__():\n",
    "        return [architecture.generator, architecture.discriminator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x (30, 128, 128, 3) float32 0.0 1.0\n",
      "train_y (30, 128, 128, 3) float32 0.0 1.0\n",
      "{'BATCH_SIZE': 30,\n",
      " 'DATA_AUGMENTATION': True,\n",
      " 'DEBUG_MODE': True,\n",
      " 'DROPOUT_PROB': 0.5,\n",
      " 'GPU': 0,\n",
      " 'IMAGE_CHANNEL': 3,\n",
      " 'IMAGE_HEIGHT': 128,\n",
      " 'IMAGE_WIDTH': 128,\n",
      " 'LEARNING_RATE': 0.01,\n",
      " 'LR_DECAY_FACTOR': 0.1,\n",
      " 'NUM_EPOCHS': 200,\n",
      " 'PRINT_EVERY': 50,\n",
      " 'SAVE_EVERY': 1,\n",
      " 'SEQUENCE_LENGTH': 10,\n",
      " 'testing_data_dir': '../data/FlyingObjectDataset_10K/testing',\n",
      " 'training_data_dir': '../data/FlyingObjectDataset_10K/training',\n",
      " 'validation_data_dir': '../data/FlyingObjectDataset_10K/validation'}\n"
     ]
    }
   ],
   "source": [
    "train_batch_generator, valid_batch_generator, test_batch_generator, nbr_train_data,nbr_valid_data, nbr_test_data = preprocess(image_shape, normalize_type=architecture.__normalization__, jitter=architecture.__jitter__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        #self.epoch = 0\n",
    "    \n",
    "    def special_compile(self, \n",
    "                d_optimizer=None, \n",
    "                g_optimizer=None,\n",
    "                d_loss=None,\n",
    "                g_loss=None,               \n",
    "                loss_fn=None,\n",
    "                metrics=None,\n",
    "                loss_weights=None,\n",
    "                weighted_metrics=None,\n",
    "                run_eagerly=None,\n",
    "                steps_per_execution=None,\n",
    "              **kwargs):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss = d_loss\n",
    "        self.g_loss = g_loss\n",
    "        \n",
    "        super().compile(metrics=metrics)\n",
    "    \n",
    "    def compile(self, **kwargs):\n",
    "        raise NotImplementedError(\"Please use special_compile()\")\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data): \n",
    "        #self.epoch += 1\n",
    "        input_image, target = data # TODO: Must check if this iterates or take same image each run\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            \n",
    "            # Generate images\n",
    "            gen_output = self.generator(input_image, training=True)\n",
    "            \n",
    "            # Train discriminator\n",
    "            disc_real_output = self.discriminator([input_image, target], training=True)\n",
    "            disc_generated_output = self.discriminator([input_image, gen_output], training=True)\n",
    "            \n",
    "            # Training\n",
    "            gen_total_loss, gen_gan_loss, gen_l1_loss = self.g_loss(disc_generated_output, gen_output, target)\n",
    "            disc_loss = self.d_loss(disc_real_output, disc_generated_output)\n",
    "            \n",
    "            # Set weights\n",
    "            generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                              self.generator.trainable_variables)\n",
    "            discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                                   self.discriminator.trainable_variables)\n",
    "            # Update weights\n",
    "            self.g_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                              self.generator.trainable_variables))\n",
    "            self.d_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                                  self.discriminator.trainable_variables))\n",
    "            \n",
    "        self.compiled_metrics.update_state(target, gen_output)\n",
    "        \n",
    "        met = {\n",
    "                'gen_total_loss':gen_total_loss,\n",
    "                'gen_gan_loss':gen_gan_loss,\n",
    "                'gen_l1_loss':gen_l1_loss,\n",
    "                'disc_loss':disc_loss, \n",
    "                \n",
    "        }\n",
    "        met.update({m.name: m.result() for m in self.metrics})\n",
    "        return met\n",
    "    \n",
    "\n",
    "    def test_step(self, data):\n",
    "        real_images, last_images = data\n",
    "        valid, fake_last_frame = self(real_images, training=False)\n",
    "\n",
    "        self.compiled_metrics.update_state(real_images, fake_last_frame)\n",
    "            \n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def call(self, first_frame, training=False):\n",
    "        fake_last_frame = self.generator(first_frame, training)\n",
    "        validate_frame = self.discriminator([fake_last_frame, first_frame], training)\n",
    "        \n",
    "        return [validate_frame, fake_last_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  1/360 [..............................] - ETA: 0s - gen_total_loss: 51.0745 - gen_gan_loss: 0.9663 - gen_l1_loss: 0.5011 - disc_loss: 0.9930 - accuracy: 0.9330 - SSIM_loss: 0.3172WARNING:tensorflow:From /home/stud/f/fremar16/miniconda3/envs/lab/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/360 [..............................] - ETA: 33s - gen_total_loss: 47.5283 - gen_gan_loss: 0.8593 - gen_l1_loss: 0.4667 - disc_loss: 0.8610 - accuracy: 0.9387 - SSIM_loss: 0.2840WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0544s vs `on_train_batch_end` time: 0.1318s). Check your callbacks.\n",
      "360/360 [==============================] - 80s 223ms/step - gen_total_loss: 3.1187 - gen_gan_loss: 0.2765 - gen_l1_loss: 0.0284 - disc_loss: 0.4825 - accuracy: 0.3017 - SSIM_loss: 0.0572 - val_accuracy: 0.2292 - val_SSIM_loss: 0.0232\n",
      "Epoch 2/200\n",
      " 53/360 [===>..........................] - ETA: 1:01 - gen_total_loss: 2.1899 - gen_gan_loss: 0.2817 - gen_l1_loss: 0.0191 - disc_loss: 0.4725 - accuracy: 0.3927 - SSIM_loss: 0.0458"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = (nbr_train_data // cfg.BATCH_SIZE) \n",
    "validation_steps=(nbr_valid_data//cfg.BATCH_SIZE)\n",
    "log_dir = logger(architecture().__name__)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, update_freq='epoch')\n",
    "\n",
    "generator, discriminator =  architecture.__model__()\n",
    "loss = architecture.loss()\n",
    "model_to_json(discriminator(), log_dir + \"/discriminator.json\")\n",
    "model_to_json(generator(), log_dir + \"/generator.json\")\n",
    "\n",
    "gan = GAN(discriminator=discriminator(), generator=generator())\n",
    "\n",
    "gan.special_compile(\n",
    "    d_optimizer=architecture.discriminator_optimizer,\n",
    "    g_optimizer=architecture.generator_optimizer,\n",
    "    d_loss=loss['d_loss_fn'],\n",
    "    g_loss=loss['g_loss_fn'],\n",
    "    metrics=['accuracy', SSIM_loss]\n",
    ")\n",
    "gan.fit(\n",
    "    x=train_batch_generator, \n",
    "    epochs=cfg.NUM_EPOCHS, \n",
    "    verbose=1, \n",
    "    batch_size=cfg.BATCH_SIZE,\n",
    "    steps_per_epoch=steps_per_epoch, #\n",
    "    validation_data=valid_batch_generator,\n",
    "    validation_steps=validation_steps, \n",
    "    callbacks=[GANMonitor(num_img=3, validation_data=valid_batch_generator,log_dir=log_dir), tensorboard_callback],\n",
    "    \n",
    ") \n",
    "\n",
    "\n",
    "with open(log_dir+\"/gan_finished\", 'a') as f:\n",
    "    f.write(architecture.__changes__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
