{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configGAN import *\n",
    "cfg = flying_objects_config()\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from utilsGAN import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "\n",
    "import imageio\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "import pprint\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv3D, Conv2D, Conv1D, Convolution2D, Deconvolution2D, Cropping2D, UpSampling2D\n",
    "from keras.layers import Input, Conv2DTranspose, ConvLSTM2D, TimeDistributed, GlobalMaxPooling2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Concatenate, concatenate, Reshape\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.layers import Input, merge\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout, LeakyReLU\n",
    "import keras.backend as kb\n",
    "from tensorflow.python.keras.engine import compile_utils\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating network model using gpu 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def limit_gpu():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "limit_gpu()\n",
    "\n",
    "if cfg.GPU >=0:\n",
    "    print(\"creating network model using gpu \" + str(cfg.GPU))\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(cfg.GPU)\n",
    "elif cfg.GPU >=-1:\n",
    "    print(\"creating network model using cpu \")  \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "##################### Training Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 10817\n",
      "total class number \t 3\n",
      "class square \t 3488 images\n",
      "class circular \t 3626 images\n",
      "class triangle \t 3703 images\n",
      "######################################################################\n",
      "\n",
      "######################################################################\n",
      "##################### Validation Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 2241\n",
      "total class number \t 3\n",
      "class triangle \t 745 images\n",
      "class square \t 783 images\n",
      "class circular \t 713 images\n",
      "######################################################################\n",
      "\n",
      "######################################################################\n",
      "##################### Testing Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 2220\n",
      "total class number \t 3\n",
      "class triangle \t 733 images\n",
      "class square \t 765 images\n",
      "class circular \t 722 images\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "show_statistics(cfg.training_data_dir, fineGrained=False, title=\" Training Data Statistics \")\n",
    "show_statistics(cfg.validation_data_dir, fineGrained=False, title=\" Validation Data Statistics \")\n",
    "show_statistics(cfg.testing_data_dir, fineGrained=False, title=\" Testing Data Statistics \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_shape = (cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH, cfg.IMAGE_CHANNEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare plots and logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from improvedUtils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class architecture:\n",
    "    __name__='Pix2Pix_model_v1'\n",
    "    __changes__=\"Changed to a pix2pix model in order to test a greater network for generator and discriminator. Generator: U-Net, Discriminator: PatchGAN\"\n",
    "    \n",
    "    __normalization__='[-1,1]'\n",
    "    \n",
    "    generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    \n",
    "    @staticmethod\n",
    "    def discriminator():\n",
    "        def downsample(filters, size, apply_batchnorm=True):\n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "            result = tf.keras.Sequential()\n",
    "            result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                     kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "            if apply_batchnorm:\n",
    "                result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "            result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "            return result\n",
    "        \n",
    "        def main():\n",
    "            \n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "            inp = tf.keras.layers.Input(shape=image_shape, name='input_image')\n",
    "            tar = tf.keras.layers.Input(shape=image_shape, name='target_image')\n",
    "\n",
    "            x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "            down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
    "            down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "            down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "            zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "            conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "            batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "            leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "            zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "            last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                        kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "            return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
    "        \n",
    "        \n",
    "        return main()\n",
    "    \n",
    "    @staticmethod\n",
    "    def generator():\n",
    "        def downsample(filters, size, apply_batchnorm=True):\n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "            result = tf.keras.Sequential()\n",
    "            result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                     kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "            if apply_batchnorm:\n",
    "                result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "            result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "            return result\n",
    "        \n",
    "        def upsample(filters, size, apply_dropout=False):\n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "            result = tf.keras.Sequential()\n",
    "            result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                            padding='same',\n",
    "                                            kernel_initializer=initializer,\n",
    "                                            use_bias=False))\n",
    "\n",
    "            result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "            if apply_dropout:\n",
    "                result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "            result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "            return result\n",
    "\n",
    "        def main():\n",
    "            inputs = tf.keras.layers.Input(shape=image_shape)\n",
    "\n",
    "            down_stack = [\n",
    "                downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "                downsample(128, 4), # (bs, 64, 64, 128)\n",
    "                downsample(256, 4), # (bs, 32, 32, 256)\n",
    "                downsample(512, 4), # (bs, 16, 16, 512)\n",
    "                downsample(512, 4), # (bs, 8, 8, 512)\n",
    "                downsample(512, 4), # (bs, 4, 4, 512)\n",
    "                downsample(512, 4), # (bs, 2, 2, 512)\n",
    "                #downsample(512, 4), # (bs, 1, 1, 512)\n",
    "            ]\n",
    "\n",
    "            up_stack = [\n",
    "                upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "                upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "                upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "                upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "                upsample(256, 4), # (bs, 32, 32, 512)\n",
    "                upsample(128, 4), # (bs, 64, 64, 256)\n",
    "                upsample(64, 4), # (bs, 128, 128, 128)\n",
    "            ]\n",
    "\n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "            last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                                 strides=2,\n",
    "                                                 padding='same',\n",
    "                                                 kernel_initializer=initializer,\n",
    "                                                 activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "            x = inputs\n",
    "\n",
    "            # Downsampling through the model\n",
    "            skips = []\n",
    "            for down in down_stack:\n",
    "                x = down(x)\n",
    "                skips.append(x)\n",
    "\n",
    "            skips = reversed(skips[:-1])\n",
    "\n",
    "            # Upsampling and establishing the skip connections\n",
    "            for up, skip in zip(up_stack, skips):\n",
    "                x = up(x)\n",
    "                x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "            x = last(x)\n",
    "\n",
    "            return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "        return main()\n",
    "    \n",
    "    def loss():  # Decided by https://arxiv.org/abs/1611.07004\n",
    "        loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        LAMBDA = 100\n",
    "        def generator_loss(disc_generated_output, gen_output, target): # https://arxiv.org/abs/1611.07004\n",
    "            gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "            # mean absolute error\n",
    "            l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "            total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "            return total_gen_loss, gan_loss, l1_loss\n",
    "\n",
    "        def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "            real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "            generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "            total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "            return total_disc_loss\n",
    "\n",
    "        return {'g_loss_fn':generator_loss, 'd_loss_fn':discriminator_loss}\n",
    "    \n",
    "    def __model__():\n",
    "        return [architecture.generator, architecture.discriminator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x (30, 128, 128, 3) float32 -1.0 1.0\n",
      "train_y (30, 128, 128, 3) float32 -1.0 1.0\n",
      "{'BATCH_SIZE': 30,\n",
      " 'DATA_AUGMENTATION': True,\n",
      " 'DEBUG_MODE': True,\n",
      " 'DROPOUT_PROB': 0.5,\n",
      " 'GPU': 0,\n",
      " 'IMAGE_CHANNEL': 3,\n",
      " 'IMAGE_HEIGHT': 128,\n",
      " 'IMAGE_WIDTH': 128,\n",
      " 'LEARNING_RATE': 0.01,\n",
      " 'LR_DECAY_FACTOR': 0.1,\n",
      " 'NUM_EPOCHS': 200,\n",
      " 'PRINT_EVERY': 50,\n",
      " 'SAVE_EVERY': 1,\n",
      " 'SEQUENCE_LENGTH': 10,\n",
      " 'testing_data_dir': '../data/FlyingObjectDataset_10K/testing',\n",
      " 'training_data_dir': '../data/FlyingObjectDataset_10K/training',\n",
      " 'validation_data_dir': '../data/FlyingObjectDataset_10K/validation'}\n"
     ]
    }
   ],
   "source": [
    "train_batch_generator, valid_batch_generator, test_batch_generator, nbr_train_data,nbr_valid_data, nbr_test_data = preprocess(image_shape, normalize_type=architecture.__normalization__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        #self.epoch = 0\n",
    "    \n",
    "    def special_compile(self, \n",
    "                d_optimizer=None, \n",
    "                g_optimizer=None,\n",
    "                d_loss=None,\n",
    "                g_loss=None,               \n",
    "                loss_fn=None,\n",
    "                metrics=None,\n",
    "                loss_weights=None,\n",
    "                weighted_metrics=None,\n",
    "                run_eagerly=None,\n",
    "                steps_per_execution=None,\n",
    "              **kwargs):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss = d_loss\n",
    "        self.g_loss = g_loss\n",
    "        \n",
    "        super().compile(metrics=metrics)\n",
    "    \n",
    "    def compile(self, **kwargs):\n",
    "        raise NotImplementedError(\"Please use special_compile()\")\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data): \n",
    "        #self.epoch += 1\n",
    "        input_image, target = data # TODO: Must check if this iterates or take same image each run\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            \n",
    "            # Generate images\n",
    "            gen_output = self.generator(input_image, training=True)\n",
    "            \n",
    "            # Train discriminator\n",
    "            disc_real_output = self.discriminator([input_image, target], training=True)\n",
    "            disc_generated_output = self.discriminator([input_image, gen_output], training=True)\n",
    "            \n",
    "            # Training\n",
    "            gen_total_loss, gen_gan_loss, gen_l1_loss = self.g_loss(disc_generated_output, gen_output, target)\n",
    "            disc_loss = self.d_loss(disc_real_output, disc_generated_output)\n",
    "            \n",
    "            # Set weights\n",
    "            generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                              self.generator.trainable_variables)\n",
    "            discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                                   self.discriminator.trainable_variables)\n",
    "            # Update weights\n",
    "            self.g_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                              self.generator.trainable_variables))\n",
    "            self.d_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                                  self.discriminator.trainable_variables))\n",
    "            \n",
    "        self.compiled_metrics.update_state(target, gen_output)\n",
    "        \n",
    "        met = {\n",
    "                'gen_total_loss':gen_total_loss,\n",
    "                'gen_gan_loss':gen_gan_loss,\n",
    "                'gen_l1_loss':gen_l1_loss,\n",
    "                'disc_loss':disc_loss, \n",
    "                \n",
    "        }\n",
    "        met.update({m.name: m.result() for m in self.metrics})\n",
    "        return met\n",
    "    \n",
    "\n",
    "    def test_step(self, data):\n",
    "        real_images, last_images = data\n",
    "        valid, fake_last_frame = self(real_images, training=False)\n",
    "\n",
    "        self.compiled_metrics.update_state(real_images, fake_last_frame)\n",
    "            \n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def call(self, first_frame, training=False):\n",
    "        fake_last_frame = self.generator(first_frame, training)\n",
    "        validate_frame = self.discriminator([fake_last_frame, first_frame], training)\n",
    "        \n",
    "        return [validate_frame, fake_last_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  1/360 [..............................] - ETA: 0s - gen_total_loss: 102.3239 - gen_gan_loss: 0.8210 - gen_l1_loss: 1.0150 - disc_loss: 1.6628 - accuracy: 0.2057 - SSIM_loss: 1.0039WARNING:tensorflow:From /home/stud/f/fremar16/miniconda3/envs/lab/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "360/360 [==============================] - 161s 446ms/step - gen_total_loss: 10.6556 - gen_gan_loss: 1.0652 - gen_l1_loss: 0.0959 - disc_loss: 1.2053 - accuracy: 0.3049 - SSIM_loss: 0.1411 - val_accuracy: 0.8796 - val_SSIM_loss: 0.1107\n",
      "Epoch 2/200\n",
      "360/360 [==============================] - 185s 513ms/step - gen_total_loss: 5.4062 - gen_gan_loss: 0.8857 - gen_l1_loss: 0.0452 - disc_loss: 1.2806 - accuracy: 0.4020 - SSIM_loss: 0.0708 - val_accuracy: 0.4207 - val_SSIM_loss: 0.1047\n",
      "Epoch 3/200\n",
      "360/360 [==============================] - 190s 527ms/step - gen_total_loss: 5.0666 - gen_gan_loss: 0.9033 - gen_l1_loss: 0.0416 - disc_loss: 1.2528 - accuracy: 0.4786 - SSIM_loss: 0.0661 - val_accuracy: 0.2436 - val_SSIM_loss: 0.0700\n",
      "Epoch 4/200\n",
      "360/360 [==============================] - 187s 519ms/step - gen_total_loss: 4.7556 - gen_gan_loss: 0.8948 - gen_l1_loss: 0.0386 - disc_loss: 1.2526 - accuracy: 0.4828 - SSIM_loss: 0.0622 - val_accuracy: 0.8373 - val_SSIM_loss: 0.0613\n",
      "Epoch 5/200\n",
      "360/360 [==============================] - 191s 530ms/step - gen_total_loss: 4.5984 - gen_gan_loss: 0.9037 - gen_l1_loss: 0.0369 - disc_loss: 1.2346 - accuracy: 0.4805 - SSIM_loss: 0.0600 - val_accuracy: 0.2172 - val_SSIM_loss: 0.0540\n",
      "Epoch 6/200\n",
      "360/360 [==============================] - 189s 524ms/step - gen_total_loss: 4.4311 - gen_gan_loss: 0.9159 - gen_l1_loss: 0.0352 - disc_loss: 1.2361 - accuracy: 0.4749 - SSIM_loss: 0.0579 - val_accuracy: 0.5811 - val_SSIM_loss: 0.0531\n",
      "Epoch 7/200\n",
      "360/360 [==============================] - 187s 519ms/step - gen_total_loss: 4.1997 - gen_gan_loss: 0.9116 - gen_l1_loss: 0.0329 - disc_loss: 1.2352 - accuracy: 0.4699 - SSIM_loss: 0.0552 - val_accuracy: 0.7436 - val_SSIM_loss: 0.0502\n",
      "Epoch 8/200\n",
      "360/360 [==============================] - 189s 526ms/step - gen_total_loss: 4.0059 - gen_gan_loss: 0.9131 - gen_l1_loss: 0.0309 - disc_loss: 1.2332 - accuracy: 0.4462 - SSIM_loss: 0.0526 - val_accuracy: 0.1280 - val_SSIM_loss: 0.0738\n",
      "Epoch 9/200\n",
      "360/360 [==============================] - 185s 515ms/step - gen_total_loss: 3.8151 - gen_gan_loss: 0.9281 - gen_l1_loss: 0.0289 - disc_loss: 1.2240 - accuracy: 0.4408 - SSIM_loss: 0.0501 - val_accuracy: 0.7518 - val_SSIM_loss: 0.0695\n",
      "Epoch 10/200\n",
      "360/360 [==============================] - 192s 532ms/step - gen_total_loss: 3.7262 - gen_gan_loss: 0.9251 - gen_l1_loss: 0.0280 - disc_loss: 1.2281 - accuracy: 0.4269 - SSIM_loss: 0.0489 - val_accuracy: 0.3998 - val_SSIM_loss: 0.0612\n",
      "Epoch 11/200\n",
      "360/360 [==============================] - 189s 524ms/step - gen_total_loss: 3.5253 - gen_gan_loss: 0.9064 - gen_l1_loss: 0.0262 - disc_loss: 1.2506 - accuracy: 0.4768 - SSIM_loss: 0.0464 - val_accuracy: 0.4588 - val_SSIM_loss: 0.0495\n",
      "Epoch 12/200\n",
      "360/360 [==============================] - 192s 533ms/step - gen_total_loss: 3.3835 - gen_gan_loss: 0.9059 - gen_l1_loss: 0.0248 - disc_loss: 1.2514 - accuracy: 0.5000 - SSIM_loss: 0.0444 - val_accuracy: 0.7864 - val_SSIM_loss: 0.0575\n",
      "Epoch 13/200\n",
      "360/360 [==============================] - 191s 531ms/step - gen_total_loss: 3.3474 - gen_gan_loss: 0.9272 - gen_l1_loss: 0.0242 - disc_loss: 1.2230 - accuracy: 0.5195 - SSIM_loss: 0.0435 - val_accuracy: 0.3380 - val_SSIM_loss: 0.0562\n",
      "Epoch 14/200\n",
      "360/360 [==============================] - 184s 510ms/step - gen_total_loss: 3.2470 - gen_gan_loss: 0.9349 - gen_l1_loss: 0.0231 - disc_loss: 1.2347 - accuracy: 0.5296 - SSIM_loss: 0.0420 - val_accuracy: 0.2916 - val_SSIM_loss: 0.0722\n",
      "Epoch 15/200\n",
      "360/360 [==============================] - 190s 527ms/step - gen_total_loss: 3.2846 - gen_gan_loss: 0.9641 - gen_l1_loss: 0.0232 - disc_loss: 1.2146 - accuracy: 0.5159 - SSIM_loss: 0.0416 - val_accuracy: 0.2011 - val_SSIM_loss: 0.0481\n",
      "Epoch 16/200\n",
      "360/360 [==============================] - 186s 517ms/step - gen_total_loss: 3.2376 - gen_gan_loss: 0.9810 - gen_l1_loss: 0.0226 - disc_loss: 1.2017 - accuracy: 0.5204 - SSIM_loss: 0.0407 - val_accuracy: 0.5648 - val_SSIM_loss: 0.0502\n",
      "Epoch 17/200\n",
      "360/360 [==============================] - 190s 528ms/step - gen_total_loss: 3.1877 - gen_gan_loss: 1.0154 - gen_l1_loss: 0.0217 - disc_loss: 1.1581 - accuracy: 0.5367 - SSIM_loss: 0.0397 - val_accuracy: 0.7278 - val_SSIM_loss: 0.0565\n",
      "Epoch 18/200\n",
      "360/360 [==============================] - 187s 520ms/step - gen_total_loss: 3.5001 - gen_gan_loss: 1.1341 - gen_l1_loss: 0.0237 - disc_loss: 1.1019 - accuracy: 0.5814 - SSIM_loss: 0.0422 - val_accuracy: 0.3803 - val_SSIM_loss: 0.0466\n",
      "Epoch 19/200\n",
      "360/360 [==============================] - 188s 523ms/step - gen_total_loss: 3.7212 - gen_gan_loss: 1.2437 - gen_l1_loss: 0.0248 - disc_loss: 1.0437 - accuracy: 0.6358 - SSIM_loss: 0.0437 - val_accuracy: 0.5122 - val_SSIM_loss: 0.0600\n",
      "Epoch 20/200\n",
      "360/360 [==============================] - 189s 526ms/step - gen_total_loss: 3.6556 - gen_gan_loss: 1.2650 - gen_l1_loss: 0.0239 - disc_loss: 1.0129 - accuracy: 0.6826 - SSIM_loss: 0.0429 - val_accuracy: 0.6367 - val_SSIM_loss: 0.0584\n",
      "Epoch 21/200\n",
      "360/360 [==============================] - 184s 512ms/step - gen_total_loss: 4.2481 - gen_gan_loss: 1.4986 - gen_l1_loss: 0.0275 - disc_loss: 0.8923 - accuracy: 0.6800 - SSIM_loss: 0.0475 - val_accuracy: 0.4815 - val_SSIM_loss: 0.0735\n",
      "Epoch 22/200\n",
      "360/360 [==============================] - 188s 523ms/step - gen_total_loss: 4.5343 - gen_gan_loss: 1.5924 - gen_l1_loss: 0.0294 - disc_loss: 0.8762 - accuracy: 0.7021 - SSIM_loss: 0.0497 - val_accuracy: 0.9317 - val_SSIM_loss: 0.0730\n",
      "Epoch 23/200\n",
      "360/360 [==============================] - 185s 513ms/step - gen_total_loss: 4.6206 - gen_gan_loss: 1.7047 - gen_l1_loss: 0.0292 - disc_loss: 0.7649 - accuracy: 0.7273 - SSIM_loss: 0.0498 - val_accuracy: 0.4436 - val_SSIM_loss: 0.0529\n",
      "Epoch 24/200\n",
      "360/360 [==============================] - 189s 525ms/step - gen_total_loss: 4.5305 - gen_gan_loss: 1.7410 - gen_l1_loss: 0.0279 - disc_loss: 0.7959 - accuracy: 0.7325 - SSIM_loss: 0.0482 - val_accuracy: 0.2834 - val_SSIM_loss: 0.0549\n",
      "Epoch 25/200\n",
      "360/360 [==============================] - 186s 517ms/step - gen_total_loss: 4.7743 - gen_gan_loss: 1.8633 - gen_l1_loss: 0.0291 - disc_loss: 0.7339 - accuracy: 0.7662 - SSIM_loss: 0.0499 - val_accuracy: 0.8212 - val_SSIM_loss: 0.0439\n",
      "Epoch 26/200\n",
      "360/360 [==============================] - 190s 528ms/step - gen_total_loss: 4.9143 - gen_gan_loss: 2.0024 - gen_l1_loss: 0.0291 - disc_loss: 0.6791 - accuracy: 0.8194 - SSIM_loss: 0.0500 - val_accuracy: 0.9372 - val_SSIM_loss: 0.0492\n",
      "Epoch 27/200\n",
      "360/360 [==============================] - 188s 522ms/step - gen_total_loss: 4.7152 - gen_gan_loss: 1.9781 - gen_l1_loss: 0.0274 - disc_loss: 0.7181 - accuracy: 0.8585 - SSIM_loss: 0.0479 - val_accuracy: 0.6781 - val_SSIM_loss: 0.0543\n",
      "Epoch 28/200\n",
      "360/360 [==============================] - 185s 515ms/step - gen_total_loss: 5.5127 - gen_gan_loss: 2.3488 - gen_l1_loss: 0.0316 - disc_loss: 0.5510 - accuracy: 0.8495 - SSIM_loss: 0.0542 - val_accuracy: 0.8512 - val_SSIM_loss: 0.0485\n",
      "Epoch 29/200\n",
      "360/360 [==============================] - 189s 526ms/step - gen_total_loss: 5.2234 - gen_gan_loss: 2.2760 - gen_l1_loss: 0.0295 - disc_loss: 0.6290 - accuracy: 0.8666 - SSIM_loss: 0.0512 - val_accuracy: 0.8669 - val_SSIM_loss: 0.0694\n",
      "Epoch 30/200\n",
      "360/360 [==============================] - 184s 512ms/step - gen_total_loss: 5.4235 - gen_gan_loss: 2.3735 - gen_l1_loss: 0.0305 - disc_loss: 0.5750 - accuracy: 0.8461 - SSIM_loss: 0.0517 - val_accuracy: 0.8720 - val_SSIM_loss: 0.0516\n",
      "Epoch 31/200\n",
      "360/360 [==============================] - 190s 528ms/step - gen_total_loss: 5.0108 - gen_gan_loss: 2.1914 - gen_l1_loss: 0.0282 - disc_loss: 0.6486 - accuracy: 0.8566 - SSIM_loss: 0.0498 - val_accuracy: 0.8726 - val_SSIM_loss: 0.0619\n",
      "Epoch 32/200\n",
      " 37/360 [==>...........................] - ETA: 2:31 - gen_total_loss: 5.2304 - gen_gan_loss: 2.3714 - gen_l1_loss: 0.0286 - disc_loss: 0.5235 - accuracy: 0.8737 - SSIM_loss: 0.0494"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = (nbr_train_data // cfg.BATCH_SIZE) \n",
    "validation_steps=(nbr_valid_data//cfg.BATCH_SIZE)\n",
    "log_dir = logger(architecture().__name__)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, update_freq='epoch')\n",
    "\n",
    "generator, discriminator =  architecture.__model__()\n",
    "loss = architecture.loss()\n",
    "model_to_json(discriminator(), log_dir + \"/discriminator.json\")\n",
    "model_to_json(generator(), log_dir + \"/generator.json\")\n",
    "\n",
    "gan = GAN(discriminator=discriminator(), generator=generator())\n",
    "\n",
    "gan.special_compile(\n",
    "    d_optimizer=architecture.discriminator_optimizer,\n",
    "    g_optimizer=architecture.generator_optimizer,\n",
    "    d_loss=loss['d_loss_fn'],\n",
    "    g_loss=loss['g_loss_fn'],\n",
    "    metrics=['accuracy', SSIM_loss]\n",
    ")\n",
    "gan.fit(\n",
    "    x=train_batch_generator, \n",
    "    epochs=cfg.NUM_EPOCHS, \n",
    "    verbose=1, \n",
    "    batch_size=cfg.BATCH_SIZE,\n",
    "    steps_per_epoch=steps_per_epoch, #\n",
    "    validation_data=valid_batch_generator,\n",
    "    validation_steps=validation_steps, \n",
    "    callbacks=[GANMonitor(num_img=3, validation_data=valid_batch_generator,log_dir=log_dir), tensorboard_callback],\n",
    "    \n",
    ") \n",
    "\n",
    "\n",
    "with open(log_dir+\"/gan_finished\", 'a') as f:\n",
    "    f.write(architecture.__changes__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
