{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configGAN import *\n",
    "cfg = flying_objects_config()\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from utilsGAN import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "from datetime import datetime\n",
    "import imageio\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "import pprint\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv3D, Conv2D, Conv1D, Convolution2D, Deconvolution2D, Cropping2D, UpSampling2D\n",
    "from keras.layers import Input, Conv2DTranspose, ConvLSTM2D, TimeDistributed, GlobalMaxPooling2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import Concatenate, concatenate, Reshape\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.layers import Input, merge\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout, LeakyReLU\n",
    "import keras.backend as kb\n",
    "from tensorflow.python.keras.engine import compile_utils\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating network model using gpu 0\n"
     ]
    }
   ],
   "source": [
    "def limit_gpu():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "limit_gpu()\n",
    "\n",
    "if cfg.GPU >=0:\n",
    "    print(\"creating network model using gpu \" + str(cfg.GPU))\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(cfg.GPU)\n",
    "elif cfg.GPU >=-1:\n",
    "    print(\"creating network model using cpu \")  \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "##################### Training Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 10817\n",
      "total class number \t 3\n",
      "class square \t 3488 images\n",
      "class circular \t 3626 images\n",
      "class triangle \t 3703 images\n",
      "######################################################################\n",
      "\n",
      "######################################################################\n",
      "##################### Validation Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 2241\n",
      "total class number \t 3\n",
      "class triangle \t 745 images\n",
      "class square \t 783 images\n",
      "class circular \t 713 images\n",
      "######################################################################\n",
      "\n",
      "######################################################################\n",
      "##################### Testing Data Statistics #####################\n",
      "######################################################################\n",
      "total image number \t 2220\n",
      "total class number \t 3\n",
      "class triangle \t 733 images\n",
      "class square \t 765 images\n",
      "class circular \t 722 images\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "show_statistics(cfg.training_data_dir, fineGrained=False, title=\" Training Data Statistics \")\n",
    "show_statistics(cfg.validation_data_dir, fineGrained=False, title=\" Validation Data Statistics \")\n",
    "show_statistics(cfg.testing_data_dir, fineGrained=False, title=\" Testing Data Statistics \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_shape = (cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH, cfg.IMAGE_CHANNEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare plots and logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from improvedUtils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class architecture:\n",
    "    __name__='Pix2Pix_model_v3'\n",
    "    __changes__=\"Changed to a pix2pix model in order to test a greater network for generator and discriminator. Generator: U-Net, Discriminator: PatchGAN. Changed Discriminator optimizer to SGD. Disable Jitter\"\n",
    "    \n",
    "    __normalization__='[-1,1]'\n",
    "    __jitter__= False\n",
    "    \n",
    "    generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    discriminator_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "    \n",
    "    @staticmethod\n",
    "    def discriminator():\n",
    "        def downsample(filters, size, apply_batchnorm=True):\n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "            result = tf.keras.Sequential()\n",
    "            result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                     kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "            if apply_batchnorm:\n",
    "                result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "            result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "            return result\n",
    "        \n",
    "        def main():\n",
    "            \n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "            inp = tf.keras.layers.Input(shape=image_shape, name='input_image')\n",
    "            tar = tf.keras.layers.Input(shape=image_shape, name='target_image')\n",
    "\n",
    "            x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "            down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
    "            down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "            down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "            zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "            conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "            batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "            leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "            zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "            last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                        kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "            return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
    "        \n",
    "        \n",
    "        return main()\n",
    "    \n",
    "    @staticmethod\n",
    "    def generator():\n",
    "        def downsample(filters, size, apply_batchnorm=True):\n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "            result = tf.keras.Sequential()\n",
    "            result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                     kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "            if apply_batchnorm:\n",
    "                result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "            result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "            return result\n",
    "        \n",
    "        def upsample(filters, size, apply_dropout=False):\n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "            result = tf.keras.Sequential()\n",
    "            result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                            padding='same',\n",
    "                                            kernel_initializer=initializer,\n",
    "                                            use_bias=False))\n",
    "\n",
    "            result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "            if apply_dropout:\n",
    "                result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "            result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "            return result\n",
    "\n",
    "        def main():\n",
    "            inputs = tf.keras.layers.Input(shape=image_shape)\n",
    "\n",
    "            down_stack = [\n",
    "                downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "                downsample(128, 4), # (bs, 64, 64, 128)\n",
    "                downsample(256, 4), # (bs, 32, 32, 256)\n",
    "                downsample(512, 4), # (bs, 16, 16, 512)\n",
    "                downsample(512, 4), # (bs, 8, 8, 512)\n",
    "                downsample(512, 4), # (bs, 4, 4, 512)\n",
    "                downsample(512, 4), # (bs, 2, 2, 512)\n",
    "                #downsample(512, 4), # (bs, 1, 1, 512)\n",
    "            ]\n",
    "\n",
    "            up_stack = [\n",
    "                upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "                upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "                upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "                upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "                upsample(256, 4), # (bs, 32, 32, 512)\n",
    "                upsample(128, 4), # (bs, 64, 64, 256)\n",
    "                upsample(64, 4), # (bs, 128, 128, 128)\n",
    "            ]\n",
    "\n",
    "            initializer = tf.random_normal_initializer(0., 0.02)\n",
    "            last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                                 strides=2,\n",
    "                                                 padding='same',\n",
    "                                                 kernel_initializer=initializer,\n",
    "                                                 activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "            x = inputs\n",
    "\n",
    "            # Downsampling through the model\n",
    "            skips = []\n",
    "            for down in down_stack:\n",
    "                x = down(x)\n",
    "                skips.append(x)\n",
    "\n",
    "            skips = reversed(skips[:-1])\n",
    "\n",
    "            # Upsampling and establishing the skip connections\n",
    "            for up, skip in zip(up_stack, skips):\n",
    "                x = up(x)\n",
    "                x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "            x = last(x)\n",
    "\n",
    "            return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "        return main()\n",
    "    \n",
    "    def loss():  # Decided by https://arxiv.org/abs/1611.07004\n",
    "        loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        LAMBDA = 100\n",
    "        def generator_loss(disc_generated_output, gen_output, target): # https://arxiv.org/abs/1611.07004\n",
    "            gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "            # mean absolute error\n",
    "            l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "            total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "            return total_gen_loss, gan_loss, l1_loss\n",
    "\n",
    "        def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "            real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "            generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "            total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "            return total_disc_loss\n",
    "\n",
    "        return {'g_loss_fn':generator_loss, 'd_loss_fn':discriminator_loss}\n",
    "    \n",
    "    def __model__():\n",
    "        return [architecture.generator, architecture.discriminator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x (30, 128, 128, 3) float32 -1.0 1.0\n",
      "train_y (30, 128, 128, 3) float32 -1.0 1.0\n",
      "{'BATCH_SIZE': 30,\n",
      " 'DATA_AUGMENTATION': True,\n",
      " 'DEBUG_MODE': True,\n",
      " 'DROPOUT_PROB': 0.5,\n",
      " 'GPU': 0,\n",
      " 'IMAGE_CHANNEL': 3,\n",
      " 'IMAGE_HEIGHT': 128,\n",
      " 'IMAGE_WIDTH': 128,\n",
      " 'LEARNING_RATE': 0.01,\n",
      " 'LR_DECAY_FACTOR': 0.1,\n",
      " 'NUM_EPOCHS': 200,\n",
      " 'PRINT_EVERY': 50,\n",
      " 'SAVE_EVERY': 1,\n",
      " 'SEQUENCE_LENGTH': 10,\n",
      " 'testing_data_dir': '../data/FlyingObjectDataset_10K/testing',\n",
      " 'training_data_dir': '../data/FlyingObjectDataset_10K/training',\n",
      " 'validation_data_dir': '../data/FlyingObjectDataset_10K/validation'}\n"
     ]
    }
   ],
   "source": [
    "train_batch_generator, valid_batch_generator, test_batch_generator, nbr_train_data,nbr_valid_data, nbr_test_data = preprocess(image_shape, normalize_type=architecture.__normalization__, jitter=architecture.__jitter__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        #self.epoch = 0\n",
    "    \n",
    "    def special_compile(self, \n",
    "                d_optimizer=None, \n",
    "                g_optimizer=None,\n",
    "                d_loss=None,\n",
    "                g_loss=None,               \n",
    "                loss_fn=None,\n",
    "                metrics=None,\n",
    "                loss_weights=None,\n",
    "                weighted_metrics=None,\n",
    "                run_eagerly=None,\n",
    "                steps_per_execution=None,\n",
    "              **kwargs):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss = d_loss\n",
    "        self.g_loss = g_loss\n",
    "        \n",
    "        super().compile(metrics=metrics)\n",
    "    \n",
    "    def compile(self, **kwargs):\n",
    "        raise NotImplementedError(\"Please use special_compile()\")\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data): \n",
    "        #self.epoch += 1\n",
    "        input_image, target = data # TODO: Must check if this iterates or take same image each run\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            \n",
    "            # Generate images\n",
    "            gen_output = self.generator(input_image, training=True)\n",
    "            \n",
    "            # Train discriminator\n",
    "            disc_real_output = self.discriminator([input_image, target], training=True)\n",
    "            disc_generated_output = self.discriminator([input_image, gen_output], training=True)\n",
    "            \n",
    "            # Training\n",
    "            gen_total_loss, gen_gan_loss, gen_l1_loss = self.g_loss(disc_generated_output, gen_output, target)\n",
    "            disc_loss = self.d_loss(disc_real_output, disc_generated_output)\n",
    "            \n",
    "            # Set weights\n",
    "            generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                              self.generator.trainable_variables)\n",
    "            discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                                   self.discriminator.trainable_variables)\n",
    "            # Update weights\n",
    "            self.g_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                              self.generator.trainable_variables))\n",
    "            self.d_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                                  self.discriminator.trainable_variables))\n",
    "            \n",
    "        self.compiled_metrics.update_state(target, gen_output)\n",
    "        \n",
    "        met = {\n",
    "                'gen_total_loss':gen_total_loss,\n",
    "                'gen_gan_loss':gen_gan_loss,\n",
    "                'gen_l1_loss':gen_l1_loss,\n",
    "                'disc_loss':disc_loss, \n",
    "                \n",
    "        }\n",
    "        met.update({m.name: m.result() for m in self.metrics})\n",
    "        return met\n",
    "    \n",
    "\n",
    "    def test_step(self, data):\n",
    "        real_images, last_images = data\n",
    "        valid, fake_last_frame = self(real_images, training=False)\n",
    "\n",
    "        self.compiled_metrics.update_state(real_images, fake_last_frame)\n",
    "            \n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def call(self, first_frame, training=False):\n",
    "        fake_last_frame = self.generator(first_frame, training)\n",
    "        validate_frame = self.discriminator([fake_last_frame, first_frame], training)\n",
    "        \n",
    "        return [validate_frame, fake_last_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  1/360 [..............................] - ETA: 0s - gen_total_loss: 98.0502 - gen_gan_loss: 1.2271 - gen_l1_loss: 0.9682 - disc_loss: 1.7182 - accuracy: 0.2836 - SSIM_loss: 0.9941WARNING:tensorflow:From /home/stud/f/fremar16/miniconda3/envs/lab/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/360 [..............................] - ETA: 1:14 - gen_total_loss: 93.5750 - gen_gan_loss: 0.9816 - gen_l1_loss: 0.9259 - disc_loss: 1.9853 - accuracy: 0.2868 - SSIM_loss: 0.9874WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0711s vs `on_train_batch_end` time: 0.3442s). Check your callbacks.\n",
      "360/360 [==============================] - 132s 365ms/step - gen_total_loss: 8.4233 - gen_gan_loss: 0.8469 - gen_l1_loss: 0.0758 - disc_loss: 1.4544 - accuracy: 0.3239 - SSIM_loss: 0.1167 - val_accuracy: 0.3383 - val_SSIM_loss: 0.1384\n",
      "Epoch 2/200\n",
      "360/360 [==============================] - 132s 366ms/step - gen_total_loss: 2.8005 - gen_gan_loss: 0.7427 - gen_l1_loss: 0.0206 - disc_loss: 1.4111 - accuracy: 0.3557 - SSIM_loss: 0.0446 - val_accuracy: 0.4651 - val_SSIM_loss: 0.0568\n",
      "Epoch 3/200\n",
      "360/360 [==============================] - 130s 361ms/step - gen_total_loss: 1.8906 - gen_gan_loss: 0.7171 - gen_l1_loss: 0.0117 - disc_loss: 1.4035 - accuracy: 0.3723 - SSIM_loss: 0.0320 - val_accuracy: 0.3556 - val_SSIM_loss: 0.0683\n",
      "Epoch 4/200\n",
      "360/360 [==============================] - 130s 361ms/step - gen_total_loss: 1.4571 - gen_gan_loss: 0.7077 - gen_l1_loss: 0.0075 - disc_loss: 1.3971 - accuracy: 0.4034 - SSIM_loss: 0.0225 - val_accuracy: 0.5022 - val_SSIM_loss: 0.0712\n",
      "Epoch 5/200\n",
      "360/360 [==============================] - 130s 362ms/step - gen_total_loss: 1.2696 - gen_gan_loss: 0.7031 - gen_l1_loss: 0.0057 - disc_loss: 1.3967 - accuracy: 0.4134 - SSIM_loss: 0.0163 - val_accuracy: 0.5765 - val_SSIM_loss: 0.0744\n",
      "Epoch 6/200\n",
      "360/360 [==============================] - 135s 374ms/step - gen_total_loss: 1.1628 - gen_gan_loss: 0.6995 - gen_l1_loss: 0.0046 - disc_loss: 1.3950 - accuracy: 0.4127 - SSIM_loss: 0.0126 - val_accuracy: 0.3191 - val_SSIM_loss: 0.0576\n",
      "Epoch 7/200\n",
      "360/360 [==============================] - 131s 364ms/step - gen_total_loss: 1.0682 - gen_gan_loss: 0.6975 - gen_l1_loss: 0.0037 - disc_loss: 1.3931 - accuracy: 0.4186 - SSIM_loss: 0.0094 - val_accuracy: 0.5193 - val_SSIM_loss: 0.0511\n",
      "Epoch 8/200\n",
      "360/360 [==============================] - 129s 360ms/step - gen_total_loss: 1.0132 - gen_gan_loss: 0.6962 - gen_l1_loss: 0.0032 - disc_loss: 1.3918 - accuracy: 0.4269 - SSIM_loss: 0.0074 - val_accuracy: 0.4882 - val_SSIM_loss: 0.0430\n",
      "Epoch 9/200\n",
      "360/360 [==============================] - 133s 368ms/step - gen_total_loss: 0.9773 - gen_gan_loss: 0.6961 - gen_l1_loss: 0.0028 - disc_loss: 1.3914 - accuracy: 0.4338 - SSIM_loss: 0.0062 - val_accuracy: 0.4737 - val_SSIM_loss: 0.0564\n",
      "Epoch 10/200\n",
      "360/360 [==============================] - 129s 360ms/step - gen_total_loss: 0.9666 - gen_gan_loss: 0.6956 - gen_l1_loss: 0.0027 - disc_loss: 1.3904 - accuracy: 0.4348 - SSIM_loss: 0.0058 - val_accuracy: 0.6713 - val_SSIM_loss: 0.0522\n",
      "Epoch 11/200\n",
      "360/360 [==============================] - 130s 361ms/step - gen_total_loss: 1.1767 - gen_gan_loss: 0.6968 - gen_l1_loss: 0.0048 - disc_loss: 1.3896 - accuracy: 0.4198 - SSIM_loss: 0.0112 - val_accuracy: 0.3665 - val_SSIM_loss: 0.0542\n",
      "Epoch 12/200\n",
      "360/360 [==============================] - 134s 371ms/step - gen_total_loss: 0.9242 - gen_gan_loss: 0.6949 - gen_l1_loss: 0.0023 - disc_loss: 1.3900 - accuracy: 0.4263 - SSIM_loss: 0.0045 - val_accuracy: 0.3831 - val_SSIM_loss: 0.0556\n",
      "Epoch 13/200\n",
      "360/360 [==============================] - 133s 369ms/step - gen_total_loss: 0.8997 - gen_gan_loss: 0.6948 - gen_l1_loss: 0.0020 - disc_loss: 1.3895 - accuracy: 0.4358 - SSIM_loss: 0.0038 - val_accuracy: 0.4267 - val_SSIM_loss: 0.0559\n",
      "Epoch 14/200\n",
      "360/360 [==============================] - 138s 382ms/step - gen_total_loss: 0.8847 - gen_gan_loss: 0.6946 - gen_l1_loss: 0.0019 - disc_loss: 1.3892 - accuracy: 0.4358 - SSIM_loss: 0.0034 - val_accuracy: 0.4784 - val_SSIM_loss: 0.0535\n",
      "Epoch 15/200\n",
      "360/360 [==============================] - 135s 376ms/step - gen_total_loss: 0.8750 - gen_gan_loss: 0.6945 - gen_l1_loss: 0.0018 - disc_loss: 1.3890 - accuracy: 0.4395 - SSIM_loss: 0.0031 - val_accuracy: 0.2836 - val_SSIM_loss: 0.0550\n",
      "Epoch 16/200\n",
      "360/360 [==============================] - 136s 378ms/step - gen_total_loss: 0.8669 - gen_gan_loss: 0.6945 - gen_l1_loss: 0.0017 - disc_loss: 1.3888 - accuracy: 0.4349 - SSIM_loss: 0.0029 - val_accuracy: 0.4692 - val_SSIM_loss: 0.0561\n",
      "Epoch 17/200\n",
      "360/360 [==============================] - 133s 371ms/step - gen_total_loss: 0.8583 - gen_gan_loss: 0.6943 - gen_l1_loss: 0.0016 - disc_loss: 1.3885 - accuracy: 0.4306 - SSIM_loss: 0.0027 - val_accuracy: 0.6515 - val_SSIM_loss: 0.0513\n",
      "Epoch 18/200\n",
      "360/360 [==============================] - 133s 370ms/step - gen_total_loss: 0.8533 - gen_gan_loss: 0.6943 - gen_l1_loss: 0.0016 - disc_loss: 1.3885 - accuracy: 0.4336 - SSIM_loss: 0.0026 - val_accuracy: 0.5006 - val_SSIM_loss: 0.0486\n",
      "Epoch 19/200\n",
      "360/360 [==============================] - 135s 374ms/step - gen_total_loss: 0.8485 - gen_gan_loss: 0.6944 - gen_l1_loss: 0.0015 - disc_loss: 1.3884 - accuracy: 0.4375 - SSIM_loss: 0.0025 - val_accuracy: 0.4585 - val_SSIM_loss: 0.0524\n",
      "Epoch 20/200\n",
      "360/360 [==============================] - 133s 370ms/step - gen_total_loss: 0.8420 - gen_gan_loss: 0.6941 - gen_l1_loss: 0.0015 - disc_loss: 1.3882 - accuracy: 0.4312 - SSIM_loss: 0.0023 - val_accuracy: 0.2415 - val_SSIM_loss: 0.0514\n",
      "Epoch 21/200\n",
      "360/360 [==============================] - 133s 370ms/step - gen_total_loss: 0.8363 - gen_gan_loss: 0.6942 - gen_l1_loss: 0.0014 - disc_loss: 1.3881 - accuracy: 0.4352 - SSIM_loss: 0.0022 - val_accuracy: 0.4521 - val_SSIM_loss: 0.0497\n",
      "Epoch 22/200\n",
      "360/360 [==============================] - 134s 372ms/step - gen_total_loss: 1.1690 - gen_gan_loss: 0.6965 - gen_l1_loss: 0.0047 - disc_loss: 1.3864 - accuracy: 0.4555 - SSIM_loss: 0.0093 - val_accuracy: 0.4171 - val_SSIM_loss: 0.0677\n",
      "Epoch 23/200\n",
      "360/360 [==============================] - 132s 365ms/step - gen_total_loss: 0.8607 - gen_gan_loss: 0.6947 - gen_l1_loss: 0.0017 - disc_loss: 1.3889 - accuracy: 0.4515 - SSIM_loss: 0.0028 - val_accuracy: 0.5442 - val_SSIM_loss: 0.0526\n",
      "Epoch 24/200\n",
      "360/360 [==============================] - 129s 358ms/step - gen_total_loss: 0.8270 - gen_gan_loss: 0.6941 - gen_l1_loss: 0.0013 - disc_loss: 1.3883 - accuracy: 0.4491 - SSIM_loss: 0.0020 - val_accuracy: 0.5424 - val_SSIM_loss: 0.0534\n",
      "Epoch 25/200\n",
      "360/360 [==============================] - 130s 362ms/step - gen_total_loss: 0.8184 - gen_gan_loss: 0.6941 - gen_l1_loss: 0.0012 - disc_loss: 1.3881 - accuracy: 0.4432 - SSIM_loss: 0.0018 - val_accuracy: 0.3593 - val_SSIM_loss: 0.0493\n",
      "Epoch 26/200\n",
      "360/360 [==============================] - 132s 368ms/step - gen_total_loss: 0.8153 - gen_gan_loss: 0.6939 - gen_l1_loss: 0.0012 - disc_loss: 1.3878 - accuracy: 0.4445 - SSIM_loss: 0.0017 - val_accuracy: 0.4819 - val_SSIM_loss: 0.0538\n",
      "Epoch 27/200\n",
      "360/360 [==============================] - 129s 359ms/step - gen_total_loss: 0.8114 - gen_gan_loss: 0.6940 - gen_l1_loss: 0.0012 - disc_loss: 1.3879 - accuracy: 0.4465 - SSIM_loss: 0.0017 - val_accuracy: 0.6109 - val_SSIM_loss: 0.0527\n",
      "Epoch 28/200\n",
      "360/360 [==============================] - 130s 361ms/step - gen_total_loss: 0.8082 - gen_gan_loss: 0.6938 - gen_l1_loss: 0.0011 - disc_loss: 1.3877 - accuracy: 0.4371 - SSIM_loss: 0.0016 - val_accuracy: 0.4400 - val_SSIM_loss: 0.0528\n",
      "Epoch 29/200\n",
      "360/360 [==============================] - 131s 363ms/step - gen_total_loss: 0.8058 - gen_gan_loss: 0.6938 - gen_l1_loss: 0.0011 - disc_loss: 1.3876 - accuracy: 0.4460 - SSIM_loss: 0.0015 - val_accuracy: 0.4938 - val_SSIM_loss: 0.0528\n",
      "Epoch 30/200\n",
      "360/360 [==============================] - 130s 361ms/step - gen_total_loss: 0.8028 - gen_gan_loss: 0.6937 - gen_l1_loss: 0.0011 - disc_loss: 1.3876 - accuracy: 0.4430 - SSIM_loss: 0.0015 - val_accuracy: 0.5302 - val_SSIM_loss: 0.0471\n",
      "Epoch 31/200\n",
      "360/360 [==============================] - 130s 360ms/step - gen_total_loss: 0.8010 - gen_gan_loss: 0.6938 - gen_l1_loss: 0.0011 - disc_loss: 1.3875 - accuracy: 0.4341 - SSIM_loss: 0.0014 - val_accuracy: 0.5853 - val_SSIM_loss: 0.0460\n",
      "Epoch 32/200\n",
      "360/360 [==============================] - 131s 364ms/step - gen_total_loss: 0.7986 - gen_gan_loss: 0.6938 - gen_l1_loss: 0.0010 - disc_loss: 1.3874 - accuracy: 0.4361 - SSIM_loss: 0.0014 - val_accuracy: 0.3838 - val_SSIM_loss: 0.0516\n",
      "Epoch 33/200\n",
      "360/360 [==============================] - 130s 361ms/step - gen_total_loss: 0.7962 - gen_gan_loss: 0.6938 - gen_l1_loss: 0.0010 - disc_loss: 1.3875 - accuracy: 0.4334 - SSIM_loss: 0.0013 - val_accuracy: 0.6048 - val_SSIM_loss: 0.0497\n",
      "Epoch 34/200\n",
      "360/360 [==============================] - 129s 359ms/step - gen_total_loss: 0.7940 - gen_gan_loss: 0.6937 - gen_l1_loss: 0.0010 - disc_loss: 1.3874 - accuracy: 0.4310 - SSIM_loss: 0.0013 - val_accuracy: 0.3769 - val_SSIM_loss: 0.0505\n",
      "Epoch 35/200\n",
      "360/360 [==============================] - 130s 362ms/step - gen_total_loss: 0.7922 - gen_gan_loss: 0.6937 - gen_l1_loss: 9.8510e-04 - disc_loss: 1.3873 - accuracy: 0.4365 - SSIM_loss: 0.0013 - val_accuracy: 0.5104 - val_SSIM_loss: 0.0541\n",
      "Epoch 36/200\n",
      "360/360 [==============================] - 132s 366ms/step - gen_total_loss: 0.7897 - gen_gan_loss: 0.6937 - gen_l1_loss: 9.5983e-04 - disc_loss: 1.3873 - accuracy: 0.4365 - SSIM_loss: 0.0012 - val_accuracy: 0.5173 - val_SSIM_loss: 0.0503\n",
      "Epoch 37/200\n",
      "360/360 [==============================] - 130s 360ms/step - gen_total_loss: 0.7883 - gen_gan_loss: 0.6937 - gen_l1_loss: 9.4595e-04 - disc_loss: 1.3873 - accuracy: 0.4363 - SSIM_loss: 0.0012 - val_accuracy: 0.5511 - val_SSIM_loss: 0.0494\n",
      "Epoch 38/200\n",
      "360/360 [==============================] - 130s 360ms/step - gen_total_loss: 1.0276 - gen_gan_loss: 0.6950 - gen_l1_loss: 0.0033 - disc_loss: 1.3864 - accuracy: 0.4984 - SSIM_loss: 0.0060 - val_accuracy: 0.6127 - val_SSIM_loss: 0.0546\n",
      "Epoch 39/200\n",
      "360/360 [==============================] - 132s 366ms/step - gen_total_loss: 0.8135 - gen_gan_loss: 0.6943 - gen_l1_loss: 0.0012 - disc_loss: 1.3879 - accuracy: 0.5014 - SSIM_loss: 0.0017 - val_accuracy: 0.5116 - val_SSIM_loss: 0.0545\n",
      "Epoch 40/200\n",
      "360/360 [==============================] - 130s 361ms/step - gen_total_loss: 0.7896 - gen_gan_loss: 0.6937 - gen_l1_loss: 9.5962e-04 - disc_loss: 1.3874 - accuracy: 0.4781 - SSIM_loss: 0.0012 - val_accuracy: 0.4678 - val_SSIM_loss: 0.0522\n",
      "Epoch 41/200\n",
      "360/360 [==============================] - 129s 359ms/step - gen_total_loss: 0.7819 - gen_gan_loss: 0.6937 - gen_l1_loss: 8.8123e-04 - disc_loss: 1.3874 - accuracy: 0.4729 - SSIM_loss: 0.0010 - val_accuracy: 0.4711 - val_SSIM_loss: 0.0505\n",
      "Epoch 42/200\n",
      "360/360 [==============================] - 132s 366ms/step - gen_total_loss: 0.7786 - gen_gan_loss: 0.6937 - gen_l1_loss: 8.4848e-04 - disc_loss: 1.3874 - accuracy: 0.4662 - SSIM_loss: 9.8229e-04 - val_accuracy: 0.4731 - val_SSIM_loss: 0.0501\n",
      "Epoch 43/200\n",
      "360/360 [==============================] - 129s 359ms/step - gen_total_loss: 0.7769 - gen_gan_loss: 0.6936 - gen_l1_loss: 8.3224e-04 - disc_loss: 1.3872 - accuracy: 0.4646 - SSIM_loss: 9.6186e-04 - val_accuracy: 0.5660 - val_SSIM_loss: 0.0511\n",
      "Epoch 44/200\n",
      "347/360 [===========================>..] - ETA: 4s - gen_total_loss: 0.7748 - gen_gan_loss: 0.6936 - gen_l1_loss: 8.1198e-04 - disc_loss: 1.3872 - accuracy: 0.4611 - SSIM_loss: 9.1672e-04"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = (nbr_train_data // cfg.BATCH_SIZE) \n",
    "validation_steps=(nbr_valid_data//cfg.BATCH_SIZE)\n",
    "log_dir = logger(architecture().__name__)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, update_freq='epoch')\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/plots/\")\n",
    "\n",
    "generator, discriminator =  architecture.__model__()\n",
    "loss = architecture.loss()\n",
    "model_to_json(discriminator(), log_dir + \"/discriminator.json\")\n",
    "model_to_json(generator(), log_dir + \"/generator.json\")\n",
    "\n",
    "gan = GAN(discriminator=discriminator(), generator=generator())\n",
    "\n",
    "gan.special_compile(\n",
    "    d_optimizer=architecture.discriminator_optimizer,\n",
    "    g_optimizer=architecture.generator_optimizer,\n",
    "    d_loss=loss['d_loss_fn'],\n",
    "    g_loss=loss['g_loss_fn'],\n",
    "    metrics=['accuracy', SSIM_loss]\n",
    ")\n",
    "gan.fit(\n",
    "    x=train_batch_generator, \n",
    "    epochs=cfg.NUM_EPOCHS, \n",
    "    verbose=1, \n",
    "    batch_size=cfg.BATCH_SIZE,\n",
    "    steps_per_epoch=steps_per_epoch, #\n",
    "    validation_data=valid_batch_generator,\n",
    "    validation_steps=validation_steps, \n",
    "    callbacks=[GANMonitor(num_img=3, validation_data=valid_batch_generator,log_dir=log_dir), tensorboard_callback],\n",
    "    \n",
    ") \n",
    "\n",
    "\n",
    "with open(log_dir+\"/gan_finished\", 'a') as f:\n",
    "    f.write(architecture.__changes__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
